{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1119748334dd18c4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Custom LLM\n",
    "This guide details the process of creating a custom Language Model (LLM) wrapper for use with Promptulate. To integrate your own LLM or an alternative to the supported wrappers, your custom LLM class must implement two essential methods.\n",
    "\n",
    "The following example shows how to create a custom LLM and use LLM to output a response to a user query. Here we wrap the OpenAI API to create a custom LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T20:57:15.393440Z",
     "start_time": "2024-04-29T20:57:12.323558Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import Field\n",
    "\n",
    "from promptulate.llms.base import BaseLLM\n",
    "from promptulate.schema import AssistantMessage, MessageSet\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your key\"\n",
    "\n",
    "\n",
    "class MyLLM(BaseLLM):\n",
    "    model: str = \"gpt-3.5-turbo\"\n",
    "    client: OpenAI = Field(default_factory=OpenAI)\n",
    "\n",
    "    def _predict(self, messages: MessageSet, *args, **kwargs) -> AssistantMessage:\n",
    "        resp = self.client.chat.completions.create(\n",
    "            model=self.model, messages=messages.listdict_messages, temperature=0.0\n",
    "        )\n",
    "        return AssistantMessage(\n",
    "            content=resp.choices[0].message.content, additional_kwargs=resp\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5b1045e297203",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If you custom a LLM class, you need to implement the `_predict` method. This method should return an `AssistantMessage` object. The `AssistantMessage` object should contain the response to the user query.\n",
    "\n",
    "## Using Your Custom LLM\n",
    "\n",
    "You can interact with your custom LLM in two ways:\n",
    "\n",
    "1. Using the __call__ Method:\n",
    "This allows you to invoke your LLM as if it were a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "116ab585029d1f87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T19:18:45.617951300Z",
     "start_time": "2024-01-10T19:18:45.597951200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is call reply\n"
     ]
    }
   ],
   "source": [
    "llm = MyLLM()\n",
    "resp: str = llm(\"How is everything going?\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea5a58c12a12f2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2. Using the `predict` Method:\n",
    "\n",
    "This method is used to get a structured response from your LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b6de96f231641de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-10T19:18:46.832877500Z",
     "start_time": "2024-01-10T19:18:46.811876800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is predict reply\n"
     ]
    }
   ],
   "source": [
    "from promptulate.schema import AssistantMessage, MessageSet, SystemMessage\n",
    "\n",
    "messages = MessageSet([SystemMessage(content=\"You are a helpful assistant.\")])\n",
    "\n",
    "llm = MyLLM()\n",
    "resp_message: AssistantMessage = llm.predict(messages)\n",
    "print(resp_message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
